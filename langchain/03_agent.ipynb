{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AburizalAN/learn-ml/blob/master/langchain/03_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXQuHtVRAXk4"
      },
      "source": [
        "# Agent\n",
        "\n",
        "## What is an Agent?\n",
        "\n",
        "Large Language Models (LLMs) are not just knowledge stores filled with information but also act as reasoning engines. They utilize their background knowledge, together with fresh information provided, to help users make decisions, reason through content, or identify next steps.\n",
        "\n",
        "LangChain's Agents are a powerful component that allows the connection of an LLM with different tools, databases, APIs, and functions. LangChain's Agent is a new and evolving area that brings exciting possibilities.\n",
        "\n",
        "LangChain agents are, therefore, a great way to employ a language model as a reasoning engine that can interactively connect to various data sources and functions.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "data data product ecommerce --> kita masukan semuanya ke vector database\n",
        "chatbot -->\n",
        "\n",
        "chatbot --> intent clf produk skincare\n",
        "\n",
        "if intent user ask_product --> jawab + RAG data dari database"
      ],
      "metadata": {
        "id": "LLfrsZJoPGsm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwrkIZiWAXk7"
      },
      "source": [
        "## Behind the Agent\n",
        "\n",
        "LangChain agents work by continuously looping through steps of action, observation, and thought.\n",
        "\n",
        "The logic behind the agent comes from the ReAct (Reason+Act) prompting, which enables the language model to take actions and reason about those actions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5j9_3Wh6AXk7"
      },
      "source": [
        "### ReAct (Reason+Act) Prompting\n",
        "\n",
        "**ReAct (Reason + Act)** is a framework for reasoning and acting in language models.\n",
        "\n",
        "ReAct allows for a synergistic relationship between reasoning and action, enhancing the model's ability to induce, track, and update action plans, handle exceptions, and interface with external sources for additional information.\n",
        "\n",
        "![ReAct](https://react-lm.github.io/files/diagram.png)\n",
        "\n",
        "ReAct improves human interpretability and trustworthiness of the models.\n",
        "\n",
        "In question answering and fact verification tasks, ReAct overcomes hallucination and error propagation issues by interacting with a external source like a Wikipedia API.\n",
        "\n",
        "In interactive decision-making benchmarks, ReAct outperforms imitation and reinforcement learning methods, showing significant improvements in success rates.\n",
        "\n",
        "![ReAct Prompt](https://tsmatz.files.wordpress.com/2023/03/20230307_paper_example.jpg?w=829)\n",
        "\n",
        "\n",
        "The Different result of using Reason Only & Act Only VS ReAct Prompting\n",
        "\n",
        "![ReAct Prompt](https://react-lm.github.io/files/hotpotqa.png)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGC7HuXvAXk7"
      },
      "source": [
        "## **Main Concept Utilizing LangChain Agents**\n",
        "\n",
        "1. **Load the Agent**\n",
        "   \n",
        "   Start by loading the desired agent from the list of supported agents. Ensure the correct string is used to reference the supported agent class.\n",
        "\n",
        "2. **Choose a Tool**\n",
        "   \n",
        "   Next, select the tool based on specific needs. Each tool serves a unique function and is designed to accept a string as input and return a string as output.\n",
        "\n",
        "3. **Interact with the Agent**\n",
        "   \n",
        "   Once the agent and tool are set up, interaction with the agent can begin by providing it with relevant input. The agent, powered by the Large Language Model (LLM), will determine the actions to take and the sequence in which they should occur.\n",
        "\n",
        "4. **Observe the Output**\n",
        "   \n",
        "   Finally, the agent will either utilize the tool and provide the output or return an output to the user, depending on the task at hand. This output can provide valuable insights or actions based on the input provided to the agent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "520nhTXGAXk8"
      },
      "source": [
        "## **Main Types of Agents**\n",
        "\n",
        "Langchain uses two main types of agents: `Action Agents` and `Plan-and-Execute Agents`.\n",
        "\n",
        "### **Action Agents**\n",
        "\n",
        "**Action Agents** take one action at a time based on user input. They decide which tool to use and what input to give to that tool. The tool is then called with the input, and an observation is recorded.\n",
        "\n",
        "This process is repeated until the agent decides it no longer needs to use a tool, and then it responds directly to the user."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4EMgrTAAXk8"
      },
      "source": [
        "**At a high-level an action agent:**\n",
        "\n",
        "1. Receives user input\n",
        "   \n",
        "2. Decides which tool, if any, to use and the tool input\n",
        "   \n",
        "3. Calls the tool and records the output (also known as an \"observation\")\n",
        "   \n",
        "4. Decides the next step using the history of tools, tool inputs, and observations\n",
        "   \n",
        "5. Repeats 3-4 until it determines it can respond directly to the user\n",
        "\n",
        "\n",
        "Action agents are wrapped in `agent executors`, chains which are responsible for calling the agent, getting back an action and action input, calling the tool that the action references with the generated input, getting the output of the tool, and then passing all that information back into the agent to get the next action it should take.\n",
        "\n",
        "**Key components of Action Agents include:**\n",
        "\n",
        "* **Agent**: Contains the application logic.\n",
        "  \n",
        "* **Tools**: Actions an agent can take.\n",
        "  \n",
        "* **Toolkits**: Groups of tools designed for a specific use case.\n",
        "  \n",
        "* **Agent Executor**: Wraps an agent and a list of tools, responsible for running the agent iteratively until the stopping criteria is met."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9CyWTGiAXk8"
      },
      "source": [
        "### **Plan and Execute Agents**\n",
        "\n",
        "**Plan-and-Execute Agents** first decide a plan of actions to take, and then execute those actions one at a time. The planner lists out the steps to take, and the executor goes through the list of steps, executing them.\n",
        "\n",
        "The most typical implementation is to have the planner be a language model, and the executor be an action agent.\n",
        "\n",
        "The power of these agents comes from the large language model itself.\n",
        "\n",
        "With clever prompt design, the workflow is put through the language model, which then instructs what to do next.\n",
        "\n",
        "**At a high-level a plan-and-execute agent:**\n",
        "\n",
        "1. Receives user input\n",
        "\n",
        "2. Plans the full sequence of steps to take\n",
        "\n",
        "3. Executes the steps in order, passing the outputs of past steps as inputs to future steps\n",
        "\n",
        "The most typical implementation is to have the planner be a language model, and the executor be an action agent.\n",
        "\n",
        "\n",
        "**An example of this is the LLM chat agent, which consists of:**\n",
        "\n",
        "* **PromptTemplate**: Instructs the language model on what to do.\n",
        "  \n",
        "* **ChatModel**: The language model that powers the agent.\n",
        "  \n",
        "* **Stop sequence**: Instructs the language model to stop generating as soon as this string is found.\n",
        "  \n",
        "* **OutputParser**: Parses the language model output into an AgentAction or AgentFinish object."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LVboOM-AXk8"
      },
      "source": [
        "## LangChain Tools\n",
        "\n",
        "A LangChain Tool is a function designed to perform a specific task.\n",
        "\n",
        "Examples of tools can range from Google Search, database lookups, Python REPL, to other chains. The standard interface for a tool is a function that accepts a string as input and returns a string as output.\n",
        "\n",
        "The standard interface for a tool is a function that accepts a string as input and returns a string as output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRFJSCyUAXk9"
      },
      "source": [
        "### Built-in Tools\n",
        "\n",
        "LangChain comes with a set of built-in tools that can be used to perform various tasks.\n",
        "\n",
        "Agents are programmed to use necessary tools depending on the type of question asked.\n",
        "\n",
        "We can find the list of all available tools in this link:\n",
        "\n",
        "https://python.langchain.com/docs/integrations/tools/\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VM4CGlBlAXk9"
      },
      "source": [
        "### Example use of Builtin tools: LLM-Math & Wikipedia\n",
        "\n",
        "Agents can also utilize databases like Wikipedia to answer questions requiring historical or specific knowledge not requiring recent data, such as details about a specific person.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASOfPiaUGPxH",
        "outputId": "94838a13-00ad-4bb5-f084-ff86c9ba8b2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.5/807.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.9/256.9 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.6/66.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k6SUMVJAXk-",
        "outputId": "b3256963-13b2-4186-8896-f814fae263bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -U wikipedia -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyNhbamXAXk9"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svdg3jnoAXk-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67135564-5dc2-4df7-9f67-d77b46a445e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "OpenAIModel = \"gpt-4\"\n",
        "llm = ChatOpenAI(model=OpenAIModel, temperature=0.1, openai_api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Rtze8LOAXk_"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools, initialize_agent\n",
        "from langchain.agents import AgentType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UT0D5gXhAXk_"
      },
      "outputs": [],
      "source": [
        "tools = load_tools([\"llm-math\"], llm=llm)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools"
      ],
      "metadata": {
        "id": "B1Th7bC6UpW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNnnOKh_AXk_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f95d986-e8dc-4434-8f7f-2680332337ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "agent= initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    handle_parsing_errors=True,\n",
        "    verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geoFw-rbAXk_",
        "outputId": "824bcf67-feb7-4a47-84cc-48fb0dd00ffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: To find 25% of 300, I need to multiply 300 by 0.25. I can use the calculator tool for this.\n",
            "\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Calculator\",\n",
            "  \"action_input\": \"300 * 0.25\"\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAnswer: 75.0\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe calculator tool has correctly calculated 25% of 300 as 75.\n",
            "Final Answer: 75\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is the 25% of 300?', 'output': '75'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "agent(\"What is the 25% of 300?\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent(\"who is president of indonesia ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1up_MKVxVE0x",
        "outputId": "2d9c7e68-4102-46c5-a25b-9baa7a30d5c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: This question is asking for a current event, which I don't have the ability to answer because I don't have real-time data access. I can only provide information up to the year 2021. As of my last update, the President of Indonesia is Joko Widodo. However, this information may have changed.\n",
            "Final Answer: As of my last update in 2021, the President of Indonesia is Joko Widodo. Please verify from a reliable source for the most current information.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'who is president of indonesia ?',\n",
              " 'output': 'As of my last update in 2021, the President of Indonesia is Joko Widodo. Please verify from a reliable source for the most current information.'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper"
      ],
      "metadata": {
        "id": "7SLY7YRPLslh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())"
      ],
      "metadata": {
        "id": "tZTTZizTLuhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools.append(wikipedia)"
      ],
      "metadata": {
        "id": "wcivRkQQLvVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tools)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIMJdOD5VQKg",
        "outputId": "17cb6951-c763-4e4a-ffac-8d596d89dfd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    handle_parsing_errors=True,\n",
        "    verbose = True)"
      ],
      "metadata": {
        "id": "-hD1Sn9MLzqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiEP6LDOAXk_",
        "outputId": "6b291c49-ca6c-4580-a290-70333e95dcb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to find out what book Tom M. Mitchell wrote. I can use the wikipedia tool to search for information about him.\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"wikipedia\",\n",
            "  \"action_input\": \"Tom M. Mitchell\"\n",
            "}\n",
            "```\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  lis = BeautifulSoup(html).find_all('li')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3mPage: Tom M. Mitchell\n",
            "Summary: Tom Michael Mitchell (born August 9, 1951) is an American computer scientist and the Founders University Professor at Carnegie Mellon University (CMU). He is a founder and former Chair of the Machine Learning Department at CMU. Mitchell is known for his contributions to the advancement of machine learning, artificial intelligence, and cognitive neuroscience and is the author of the textbook Machine Learning. He is a member of the United States National Academy of Engineering since 2010. He is also a Fellow of the American Academy of Arts and Sciences, the American Association for the Advancement of Science and a Fellow and past President of the Association for the Advancement of Artificial Intelligence. In October 2018, Mitchell was appointed as the Interim Dean of the School of Computer Science at Carnegie Mellon.\n",
            "\n",
            "\n",
            "\n",
            "Page: Oren Etzioni\n",
            "Summary: Oren Etzioni (born 1964) is an American entrepreneur, Professor Emeritus of computer science, and founding CEO of the Allen Institute for Artificial Intelligence (AI2). On June 15, 2022, he announced that he will step down as CEO of AI2 effective September 30, 2022. After that time, he will continue as a board member and advisor. Etzioni will also take the position of Technical Director of the AI2 Incubator.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe Wikipedia search provided information that Tom M. Mitchell is the author of the textbook \"Machine Learning\". \n",
            "Final Answer: Tom M. Mitchell wrote the book \"Machine Learning\".\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "question = \"Tom M. Mitchell is an American computer scientist \\\n",
        "and the Founders University Professor at Carnegie Mellon University (CMU)\\\n",
        "what book did he write?\"\n",
        "\n",
        "result = agent(question)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent(\"who is president of indonesia ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uB2iwQ3yVlzU",
        "outputId": "2367d5ae-a582-44a8-e4bd-f60bc6536b5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to find out who the current president of Indonesia is. I can use the wikipedia tool to find this information.\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"wikipedia\",\n",
            "  \"action_input\": \"President of Indonesia\"\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mPage: President of Indonesia\n",
            "Summary: The president of the Republic of Indonesia (Indonesian: Presiden Republik Indonesia) is the head of state and head of government of the Republic of Indonesia. The president leads the executive branch of the Indonesian government and is the commander-in-chief of Indonesian National Armed Forces and Indonesian National Police. Since 2004, the president and vice president are directly elected to a five-year term, once renewable, allowing for a maximum of 10 years in office.\n",
            "Joko Widodo is the 7th and current president of Indonesia. He assumed office on 20 October 2014.\n",
            "\n",
            "Page: List of presidents of Indonesia\n",
            "Summary: The president is the head of state and also head of government of the Republic of Indonesia. The president leads the executive branch of the Indonesian government and is the commander-in-chief of the Indonesian National Armed Forces. Since 2004, the president and vice president are directly elected to a five-year term.The presidency was established during the formulation of the 1945 constitution by the Investigating Committee for Preparatory Work for Independence (BPUPK), a body established by the occupying Japanese 16th Army on 1 March 1945 to work on \"preparations for independence in the region of the government of this island of Java\". On 18 August 1945, the Preparatory Committee for Indonesian Independence (PPKI), which was created on 7 August to replace the BPUPK, selected Sukarno as the country's first president.\n",
            "\n",
            "Page: Vice President of Indonesia\n",
            "Summary: The vice president of the Republic of Indonesia (Indonesian: Wakil Presiden Republik Indonesia) is second-highest officer in the executive branch of the Indonesian government, after the president, and ranks first in the presidential line of succession. Since 2004, the president and vice president are directly elected to a five-year term.\n",
            "Ma'ruf Amin is the 13th and current vice president of Indonesia. He assumed office on 20 October 2019.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe current president of Indonesia is Joko Widodo. He assumed office on 20 October 2014. \n",
            "Final Answer: The current president of Indonesia is Joko Widodo.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'who is president of indonesia ?',\n",
              " 'output': 'The current president of Indonesia is Joko Widodo.'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltQa8g6bAXk_"
      },
      "source": [
        "### Python Agent"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_experimental langchainhub -q"
      ],
      "metadata": {
        "id": "6Rog_2llHatC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce16c68b-6748-4e78-b094-39103d0805d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/173.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/173.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.7/173.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLBK9xF1AXlA"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor\n",
        "from langchain_experimental.tools import PythonREPLTool\n",
        "from langchain.agents import create_react_agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HF-W32RYAXlA"
      },
      "outputs": [],
      "source": [
        "instructions = \"\"\"You are an agent designed to write and execute python code to answer questions.\n",
        "You have access to a python REPL, which you can use to execute python code.\n",
        "If you get an error, debug your code and try again.\n",
        "Only use the output of your code to answer the question.\n",
        "You might know the answer without running any code, but you should still run the code to get the answer.\n",
        "If it does not seem like you can write code to answer the question, just return \"I don't know\" as the answer.\n",
        "\"\"\"\n",
        "base_prompt = hub.pull(\"langchain-ai/react-agent-template\")\n",
        "prompt = base_prompt.partial(instructions=instructions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools.append(PythonREPLTool())"
      ],
      "metadata": {
        "id": "hvS739naI92z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tools)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbXAeUYMWC0E",
        "outputId": "2c171f0a-187b-4963-8612-bce9efd40387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_react_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)"
      ],
      "metadata": {
        "id": "FcXzOsQlINfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GSza8wLAXlA",
        "outputId": "2c6ce10f-6d42-4ec3-a0d6-116b02ee8335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_experimental.utilities.python:Python REPL can execute arbitrary code. Use with caution.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: Python_REPL\n",
            "Action Input: \n",
            "```python\n",
            "def fibonacci(n):\n",
            "    if n <= 0:\n",
            "        return \"Input should be positive integer\"\n",
            "    elif n == 1:\n",
            "        return 0\n",
            "    elif n == 2:\n",
            "        return 1\n",
            "    else:\n",
            "        a, b = 0, 1\n",
            "        for _ in range(2, n):\n",
            "            a, b = b, a + b\n",
            "        return b\n",
            "\n",
            "fibonacci(10)\n",
            "```\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
            "Final Answer: 34\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is the 10th fibonacci number?', 'output': '34'}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "agent_executor.invoke({\"input\": \"What is the 10th fibonacci number?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qWUjrqrAXlA"
      },
      "source": [
        "## Custom-made Tools\n",
        "\n",
        "LangChain users can create their custom-made tools through the tool decorator and connect their agent to their preferred data sources.\n",
        "\n",
        "An example of a custom-made tool can be a function that returns the current date. The function is added to the agent's list of tools, and when asked, the agent can accurately tell the current date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8WEzLznAXlA"
      },
      "outputs": [],
      "source": [
        "from datetime import date\n",
        "from langchain.agents import tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycMKWHAmAXlA"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def time(text: str) -> str:\n",
        "    \"\"\"Returns todays date, use this for any \\\n",
        "    questions related to knowing todays date. \\\n",
        "    The input should always be an empty string, \\\n",
        "    and this function will always return todays \\\n",
        "    date - any date mathmatics should occur \\\n",
        "    outside this function.\"\"\"\n",
        "    return str(date.today())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(time.name)\n",
        "print(time.description)\n",
        "print(time.args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-P62m3glKi3-",
        "outputId": "2e34b30d-d13a-4d12-e76f-292c7e2083b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time\n",
            "time(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,     and this function will always return todays     date - any date mathmatics should occur     outside this function.\n",
            "{'text': {'title': 'Text', 'type': 'string'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools.append(time)"
      ],
      "metadata": {
        "id": "PMjwQBOOKP1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31nq8biPAXlA"
      },
      "outputs": [],
      "source": [
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    handle_parsing_errors=True,\n",
        "    verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "uRh4Is-TAXlA",
        "outputId": "16ac801a-30ad-4f02-9ec4-919c970ab057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to get today's date and then add one day to it. I can use the 'time' tool to get today's date and then use the 'Python_REPL' tool to add one day to it.\n",
            "\n",
            "Action: \n",
            "```\n",
            "{\n",
            "  \"action\": \"time\",\n",
            "  \"action_input\": \"\"\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m2024-03-08\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mNow I have today's date. I need to add one day to it. I can use the 'Python_REPL' tool to do this. I will convert the date string to a datetime object, add one day, and then convert it back to a string. \n",
            "\n",
            "Action: \n",
            "```\n",
            "{\n",
            "  \"action\": \"Python_REPL\",\n",
            "  \"action_input\": \"from datetime import datetime, timedelta; date_format = '%Y-%m-%d'; today = datetime.strptime('2024-03-08', date_format); tomorrow = today + timedelta(days=1); tomorrow.strftime(date_format)\"\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now have the date for tomorrow.\n",
            "Final Answer: 2024-03-09\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2024-03-09'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "agent.run(f\"\"\"What date is tomorrow?\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjvNY2dZAXlA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}